{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "#from torchtext import data, datasets\n",
    "#from torchtext.vocab import Vocab\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import dask\n",
    "import math\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "dask.config.set({'array.slicing.split_large_chunks': False})\n",
    "from datagenerator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open data from WeatherBench\n",
    "DATADIR = '/Users/noeliaotero/Documents/CAS_ML/WeatherBench-master/data/WeatherBench/5.625deg/'\n",
    "# Load the entire dataset\n",
    "z500 = xr.open_mfdataset(f'{DATADIR}geopotential_500/*.nc', combine='by_coords').z\n",
    "t850 = xr.open_mfdataset(f'{DATADIR}temperature_850/*.nc', combine='by_coords').t.drop('level')\n",
    "ds = xr.merge([z500, t850])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only load a subset of the training data\n",
    "ds_train = ds.sel(time=slice('2015', '2016'))  \n",
    "ds_test = ds.sel(time=slice('2017', '2018'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into RAM\n",
      "Loading data into RAM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# then we need a dictionary for all the variables and levels we want to extract from the dataset\n",
    "dic = OrderedDict({'z': None, 't': None})\n",
    "lead_time =1\n",
    "bs = 32\n",
    "# Create a training and validation data generator. Use the train mean and std for validation as well.\n",
    "dg_train = DataGenerator(\n",
    "    ds_train.sel(time=slice('2015', '2015')), dic, lead_time, batch_size=bs, load=True)\n",
    "dg_valid = DataGenerator(\n",
    "    ds_train.sel(time=slice('2016', '2016')), dic, lead_time, batch_size=bs, mean=dg_train.mean, std=dg_train.std, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Define positional encoding\n",
    "def getPositionEncoding(sequence_len, output_dim, n=10000):\n",
    "    P = torch.zeros((sequence_len, output_dim))\n",
    "    for k in range(sequence_len):\n",
    "        for i in torch.arange(int(output_dim/2)):\n",
    "            denominator = torch.pow(torch.Tensor([n]), torch.Tensor([2*i/output_dim]))\n",
    "            P[k, 2*i] = torch.sin(k/denominator)\n",
    "            P[k, 2*i+1] = torch.cos(k/denominator)\n",
    "    return P\n",
    "\n",
    "P = getPositionEncoding(sequence_len=4, output_dim=4, n=100)\n",
    "print(P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4])\n"
     ]
    }
   ],
   "source": [
    "P=getPositionEncoding(sequence_len=32, output_dim=4, n=100)\n",
    "print(P.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python CASM6",
   "language": "python",
   "name": "casm6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "89acc57343a2b9c233d3a03eb936ce8fe371fffead8157434df0be7232f9cdb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
